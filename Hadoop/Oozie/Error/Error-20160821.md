2016-08-21 11:21:54,386  WARN SparkActionExecutor:523 - SERVER[sandbox.hortonworks.com] USER[oozie] GROUP[-] TOKEN[] APP[SparkFileCopy] JOB[0000000-160821103021876-oozie-oozi-W] ACTION[0000000-160821103021876-oozie-oozi-W@spark-node] Launcher ERROR, reason: Main class [org.apache.oozie.action.hadoop.SparkMain], main() threw exception, com.google.common.hash.HashFunction.hashInt(I)Lcom/google/common/hash/HashCode;
2016-08-21 11:21:54,386  WARN SparkActionExecutor:523 - SERVER[sandbox.hortonworks.com] USER[oozie] GROUP[-] TOKEN[] APP[SparkFileCopy] JOB[0000000-160821103021876-oozie-oozi-W] ACTION[0000000-160821103021876-oozie-oozi-W@spark-node] Launcher exception: com.google.common.hash.HashFunction.hashInt(I)Lcom/google/common/hash/HashCode;
java.lang.NoSuchMethodError: com.google.common.hash.HashFunction.hashInt(I)Lcom/google/common/hash/HashCode;
	at org.apache.spark.util.collection.OpenHashSet.org$apache$spark$util$collection$OpenHashSet$$hashcode(OpenHashSet.scala:261)
	at org.apache.spark.util.collection.OpenHashSet$mcI$sp.getPos$mcI$sp(OpenHashSet.scala:165)
	at org.apache.spark.util.collection.OpenHashSet$mcI$sp.contains$mcI$sp(OpenHashSet.scala:102)
	at org.apache.spark.util.SizeEstimator$$anonfun$visitArray$2.apply$mcVI$sp(SizeEstimator.scala:214)
	at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
	at org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:210)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:169)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:161)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:155)
	at org.apache.spark.util.collection.SizeTracker$class.takeSample(SizeTracker.scala:78)
	at org.apache.spark.util.collection.SizeTracker$class.afterUpdate(SizeTracker.scala:70)
	at org.apache.spark.util.collection.SizeTrackingVector.$plus$eq(SizeTrackingVector.scala:31)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:236)
	at org.apache.spark.storage.MemoryStore.putIterator(MemoryStore.scala:126)
	at org.apache.spark.storage.MemoryStore.putIterator(MemoryStore.scala:104)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:743)
	at org.apache.spark.storage.BlockManager.putIterator(BlockManager.scala:594)
	at org.apache.spark.storage.BlockManager.putSingle(BlockManager.scala:865)
	at org.apache.spark.broadcast.TorrentBroadcast.writeBlocks(TorrentBroadcast.scala:79)
	at org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:68)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:36)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:29)
	at org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:62)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:809)
	at org.apache.spark.SparkContext.hadoopFile(SparkContext.scala:559)
	at org.apache.spark.SparkContext.textFile(SparkContext.scala:471)
	at org.apache.spark.api.java.JavaSparkContext.textFile(JavaSparkContext.scala:174)
	at org.apache.oozie.example.SparkFileCopy.main(SparkFileCopy.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:328)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
	at org.apache.oozie.action.hadoop.SparkMain.runSpark(SparkMain.java:104)
	at org.apache.oozie.action.hadoop.SparkMain.run(SparkMain.java:95)
	at org.apache.oozie.action.hadoop.LauncherMain.run(LauncherMain.java:47)
	at org.apache.oozie.action.hadoop.SparkMain.main(SparkMain.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.oozie.action.hadoop.LauncherMapper.map(LauncherMapper.java:241)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)

2016-08-21 11:21:54,910  INFO ActionEndXCommand:520 - SERVER[sandbox.hortonworks.com] USER[oozie] GROUP[-] TOKEN[] APP[SparkFileCopy] JOB[0000000-160821103021876-oozie-oozi-W] ACTION[0000000-160821103021876-oozie-oozi-W@spark-node] ERROR is considered as FAILED for SLA

错误原因可能是：
guava-11.0.2.jar 冲突，引用的jar包中并不包含“hashInt”方法
问题是该更换哪里的jar包才能解决问题？

--------------------------------------------------------------------------------

解决尝试1：
替换了/usr/hdp/2.x/oozie 目录下的 "lib" "libserver" "libtools" 目录下的所有guava.jar
更新至18版本。重启oozie

结论：试验后仍然报错，貌似和oozie的lib没有关系。

解决尝试2：
替换了yarn的 guava.jar
失败

尝试后发觉应该和安装的程序中的lib包没有关系。可能和hdfs上的依赖jar包有关系。
解决尝试3：
替换了hdfs://xx:8020/user/oozie/share/lib/lib_xxx/ 下spark和oozie的guava.jar  发现不管用。
然后替换了所有lib_xxx下的子目录里面的guava.jar 文件再测试。
全部都不对。

删了share里的guava.jar包，报缺少jar文件错误，看来jar包就是在share目录指定，可能替换了jar包需要重启吧，先把jar包名字换了试试。

报错：Futures timed out after [10000 milliseconds]
【未完待续】
